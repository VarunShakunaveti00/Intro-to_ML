{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "All the imports required."
      ],
      "metadata": {
        "id": "XLuZkq0XHT0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import argparse"
      ],
      "metadata": {
        "id": "SBW-EqCN8nL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the data is in Unicode format, we first convert it to ASCII and remove all non-letter characters to standardize the text. We then simplify our dataset by filtering out sentence pairs where the English sentence exceeds ten tokens. These filtered pairs are saved to a new file named processed_eng-fra.txt.\n",
        "\n",
        "To further simplify the dataset, we consider the sentence pairs where the English sentence starts with a specific set of prefixes. Finally, we generate the vocabularies of all English and French words present in the filtered dataset."
      ],
      "metadata": {
        "id": "jV-twIarHZxG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA82p8avBvMo",
        "outputId": "7e5311e2-36fb-48e1-a9b5-f48d6b866a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English vocabulary size: 3381\n",
            "French vocabulary size: 5129\n",
            "Sample English words: [('<pad>', 0), ('<sos>', 1), ('<eos>', 2), ('i', 3), ('m', 4), ('ok', 5), ('fat', 6), ('fit', 7), ('hit', 8), ('ill', 9)]\n",
            "Sample French words: [('<pad>', 0), ('<sos>', 1), ('<eos>', 2), ('j', 3), ('ai', 4), ('ans', 5), ('je', 6), ('vais', 7), ('bien', 8), ('ca', 9)]\n",
            "Processed 135842 lines\n",
            "Filtered out 122933 lines\n",
            "  - 122377 without required prefix\n",
            "  - 556 with more than 10 tokens\n",
            "Remaining: 12909 lines\n",
            "First 5 processed examples:\n",
            "i m \tj ai ans \n",
            "i m ok \tje vais bien \n",
            "i m ok \tca va \n",
            "i m fat \tje suis gras \n",
            "i m fat \tje suis gros \n"
          ]
        }
      ],
      "source": [
        "def unicodeToAscii(s):\n",
        "    \"\"\"Convert Unicode string to ASCII\"\"\"\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(\"[.!?]\", '', s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "def process_file(input_file, output_file, max_tokens=10):\n",
        "    \"\"\"Process the entire file and write to output\"\"\"\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        lines = f.read().strip().split('\\n')\n",
        "\n",
        "    eng_prefixes = (\n",
        "        \"i am \", \"i m \",\n",
        "        \"he is\", \"he s \",\n",
        "        \"she is\", \"she s\",\n",
        "        \"you are\", \"you re \",\n",
        "        \"we are\", \"we re \",\n",
        "        \"they are\", \"they re \"\n",
        "    )\n",
        "\n",
        "    processed_lines = []\n",
        "    filtered_count = 0\n",
        "    total_count = 0\n",
        "    prefix_filtered = 0\n",
        "\n",
        "    for line in lines:\n",
        "        total_count += 1\n",
        "        parts = line.split('\\t')\n",
        "        processed_parts = [normalizeString(part) for part in parts]\n",
        "\n",
        "        eng_part = processed_parts[0]\n",
        "        eng_tokens = eng_part.split()\n",
        "\n",
        "        has_prefix = any(eng_part.startswith(prefix) for prefix in eng_prefixes)\n",
        "\n",
        "        if len(eng_tokens) <= max_tokens and has_prefix:\n",
        "            processed_lines.append('\\t'.join(processed_parts))\n",
        "        else:\n",
        "            filtered_count += 1\n",
        "            if not has_prefix:\n",
        "                prefix_filtered += 1\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(processed_lines))\n",
        "\n",
        "    print(f\"Processed {total_count} lines\")\n",
        "    print(f\"Filtered out {filtered_count} lines\")\n",
        "    print(f\"  - {prefix_filtered} without required prefix\")\n",
        "    print(f\"  - {filtered_count - prefix_filtered} with more than {max_tokens} tokens\")\n",
        "    print(f\"Remaining: {len(processed_lines)} lines\")\n",
        "    print(f\"First 5 processed examples:\")\n",
        "    for i in range(min(5, len(processed_lines))):\n",
        "        print(processed_lines[i])\n",
        "\n",
        "PAD_token = 0\n",
        "SOS_token = 1\n",
        "EOS_token = 2\n",
        "\n",
        "def build_vocab_from_data(pairs, max_vocab_size=None):\n",
        "    \"\"\"\n",
        "    Build vocabularies for source and target languages\n",
        "\n",
        "    Args:\n",
        "        pairs: List of sentence pairs [English, French]\n",
        "        max_vocab_size: Optional limit on vocabulary size\n",
        "\n",
        "    Returns:\n",
        "        source_vocab: Dictionary mapping English words to indices\n",
        "        source_index2word: Dictionary mapping indices to English words\n",
        "        target_vocab: Dictionary mapping French words to indices\n",
        "        target_index2word: Dictionary mapping indices to French words\n",
        "    \"\"\"\n",
        "    source_vocab = {\"<pad>\": PAD_token, \"<sos>\": SOS_token, \"<eos>\": EOS_token}\n",
        "    target_vocab = {\"<pad>\": PAD_token, \"<sos>\": SOS_token, \"<eos>\": EOS_token}\n",
        "\n",
        "    source_index2word = {PAD_token: \"<pad>\", SOS_token: \"<sos>\", EOS_token: \"<eos>\"}\n",
        "    target_index2word = {PAD_token: \"<pad>\", SOS_token: \"<sos>\", EOS_token: \"<eos>\"}\n",
        "\n",
        "    source_word_count = {}\n",
        "    target_word_count = {}\n",
        "\n",
        "    for pair in pairs:\n",
        "        for word in pair[0].split():\n",
        "            if word not in source_word_count:\n",
        "                source_word_count[word] = 1\n",
        "            else:\n",
        "                source_word_count[word] += 1\n",
        "\n",
        "        for word in pair[1].split():\n",
        "            if word not in target_word_count:\n",
        "                target_word_count[word] = 1\n",
        "            else:\n",
        "                target_word_count[word] += 1\n",
        "\n",
        "    source_index = 3\n",
        "    target_index = 3\n",
        "\n",
        "    if max_vocab_size:\n",
        "        source_sorted = sorted(source_word_count.items(), key=lambda x: x[1], reverse=True)\n",
        "        target_sorted = sorted(target_word_count.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        for word, _ in source_sorted[:max_vocab_size - 3]:\n",
        "            source_vocab[word] = source_index\n",
        "            source_index2word[source_index] = word\n",
        "            source_index += 1\n",
        "\n",
        "        for word, _ in target_sorted[:max_vocab_size - 3]:\n",
        "            target_vocab[word] = target_index\n",
        "            target_index2word[target_index] = word\n",
        "            target_index += 1\n",
        "    else:\n",
        "        for word in source_word_count:\n",
        "            source_vocab[word] = source_index\n",
        "            source_index2word[source_index] = word\n",
        "            source_index += 1\n",
        "\n",
        "        for word in target_word_count:\n",
        "            target_vocab[word] = target_index\n",
        "            target_index2word[target_index] = word\n",
        "            target_index += 1\n",
        "\n",
        "    return source_vocab, source_index2word, target_vocab, target_index2word, source_index, target_index\n",
        "\n",
        "def load_sentence_pairs(file_path):\n",
        "    \"\"\"Load sentence pairs from the processed file\"\"\"\n",
        "    pairs = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) == 2:\n",
        "                pairs.append(parts)\n",
        "    return pairs\n",
        "\n",
        "pairs = load_sentence_pairs('processed_eng_fra.txt')\n",
        "eng_vocab, eng_index2word, fra_vocab, fra_index2word, eng_vocab_size, fra_vocab_size = build_vocab_from_data(pairs)\n",
        "\n",
        "print(f\"English vocabulary size: {eng_vocab_size}\")\n",
        "print(f\"French vocabulary size: {fra_vocab_size}\")\n",
        "print(f\"Sample English words: {list(eng_vocab.items())[:10]}\")\n",
        "print(f\"Sample French words: {list(fra_vocab.items())[:10]}\")\n",
        "\n",
        "def sentence_to_indices(sentence, vocab, max_length, add_sos_eos=True):\n",
        "    \"\"\"Convert a sentence to a list of indices\"\"\"\n",
        "    words = sentence.split()\n",
        "    indices = []\n",
        "\n",
        "    if add_sos_eos:\n",
        "        indices.append(SOS_token)\n",
        "\n",
        "    for word in words:\n",
        "        if word in vocab:\n",
        "            indices.append(vocab[word])\n",
        "        else:\n",
        "            indices.append(PAD_token)\n",
        "\n",
        "    if add_sos_eos:\n",
        "        indices.append(EOS_token)\n",
        "\n",
        "    if len(indices) > max_length:\n",
        "        indices = indices[:max_length]\n",
        "    else:\n",
        "        indices += [PAD_token] * (max_length - len(indices))\n",
        "\n",
        "    return indices\n",
        "\n",
        "def indices_to_sentence(indices, index2word):\n",
        "    \"\"\"Convert a list of indices to a sentence\"\"\"\n",
        "    words = []\n",
        "    for idx in indices:\n",
        "        if idx == EOS_token:\n",
        "            break\n",
        "        elif idx != SOS_token and idx != PAD_token:\n",
        "            words.append(index2word[idx])\n",
        "    return ' '.join(words)\n",
        "\n",
        "process_file('eng-fra.txt', 'processed_eng_fra.txt', max_tokens=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the main module, where we define the encoder and decoder and the linear connector bridge between them. The encoder used here is a bidirectional LSTM and the decoder is an LSTM."
      ],
      "metadata": {
        "id": "tmPJJ7uSKflx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.1):\n",
        "        \"\"\"Bidirectional LSTM encoder\"\"\"\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers,\n",
        "                            batch_first=True, bidirectional=True, dropout=dropout if num_layers > 1 else 0)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"Initialize weights with smaller values to prevent gradient explosion\"\"\"\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight_ih' in name:\n",
        "                nn.init.xavier_uniform_(param.data, gain=0.5)\n",
        "            elif 'weight_hh' in name:\n",
        "                nn.init.orthogonal_(param.data, gain=0.5)\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param.data, 0)\n",
        "            elif 'embedding.weight' in name:\n",
        "                nn.init.uniform_(param.data, -0.1, 0.1)\n",
        "\n",
        "    def forward(self, input_seq, hidden=None):\n",
        "        \"\"\"\n",
        "        input_seq: batch_size x seq_len\n",
        "        \"\"\"\n",
        "        embedded = self.dropout(self.embedding(input_seq))\n",
        "        outputs, (hidden, cell) = self.lstm(embedded, hidden)\n",
        "        return outputs, (hidden, cell)\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_layers=1, dropout=0.1):\n",
        "        \"\"\"LSTM decoder\"\"\"\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers,\n",
        "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"Initialize weights with smaller values to prevent gradient explosion\"\"\"\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight_ih' in name:\n",
        "                nn.init.xavier_uniform_(param.data, gain=0.5)\n",
        "            elif 'weight_hh' in name:\n",
        "                nn.init.orthogonal_(param.data, gain=0.5)\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param.data, 0)\n",
        "            elif 'embedding.weight' in name:\n",
        "                nn.init.uniform_(param.data, -0.1, 0.1)\n",
        "            elif 'out.weight' in name:\n",
        "                nn.init.xavier_uniform_(param.data, gain=0.5)\n",
        "\n",
        "    def forward(self, input_token, hidden):\n",
        "        \"\"\"\n",
        "        input_token: batch_size tensor of indices\n",
        "        hidden: tuple of (hidden_state, cell_state)\n",
        "        \"\"\"\n",
        "        if input_token.dim() > 1:\n",
        "            input_token = input_token.squeeze(-1)\n",
        "        embedded = self.embedding(input_token).unsqueeze(1)\n",
        "        embedded = self.dropout(embedded)\n",
        "        lstm_out, hidden = self.lstm(embedded, hidden)\n",
        "        output = self.out(lstm_out.squeeze(1))\n",
        "        return output, hidden\n",
        "\n",
        "class EncoderDecoderConnector(nn.Module):\n",
        "    def __init__(self, encoder_hidden_size, decoder_hidden_size, num_layers=1):\n",
        "        \"\"\"Linear layer to connect bidirectional encoder to unidirectional decoder\"\"\"\n",
        "        super(EncoderDecoderConnector, self).__init__()\n",
        "        self.hidden_connector = nn.Linear(encoder_hidden_size * 2, decoder_hidden_size)\n",
        "        self.cell_connector = nn.Linear(encoder_hidden_size * 2, decoder_hidden_size)\n",
        "        self.num_layers = num_layers\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"Initialize weights with smaller values to prevent gradient explosion\"\"\"\n",
        "        nn.init.xavier_uniform_(self.hidden_connector.weight, gain=0.5)\n",
        "        nn.init.constant_(self.hidden_connector.bias, 0)\n",
        "        nn.init.xavier_uniform_(self.cell_connector.weight, gain=0.5)\n",
        "        nn.init.constant_(self.cell_connector.bias, 0)\n",
        "\n",
        "    def forward(self, encoder_hidden, encoder_cell):\n",
        "        \"\"\"\n",
        "        Reshape and transform encoder final states for decoder initial states\n",
        "        encoder_hidden: 2*num_layers x batch_size x hidden_size\n",
        "        encoder_cell: 2*num_layers x batch_size x hidden_size\n",
        "        \"\"\"\n",
        "        decoder_hidden = []\n",
        "        decoder_cell = []\n",
        "        for l in range(self.num_layers):\n",
        "            idx_forward = l * 2\n",
        "            idx_backward = l * 2 + 1\n",
        "            hidden_concat = torch.cat([encoder_hidden[idx_forward], encoder_hidden[idx_backward]], dim=1)\n",
        "            cell_concat = torch.cat([encoder_cell[idx_forward], encoder_cell[idx_backward]], dim=1)\n",
        "            decoder_hidden.append(torch.tanh(self.hidden_connector(hidden_concat)).unsqueeze(0))\n",
        "            decoder_cell.append(torch.tanh(self.cell_connector(cell_concat)).unsqueeze(0))\n",
        "        decoder_hidden = torch.cat(decoder_hidden, dim=0)\n",
        "        decoder_cell = torch.cat(decoder_cell, dim=0)\n",
        "        return decoder_hidden, decoder_cell"
      ],
      "metadata": {
        "id": "naEzIJ4ZCTuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use teacher forcing to train the model and also we use the gradient clippling provided by pytorch."
      ],
      "metadata": {
        "id": "lqxuoNWBK7Z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader(pairs, src_vocab, tgt_vocab, batch_size, max_input_length, max_output_length):\n",
        "    \"\"\"Create batched DataLoader from sentence pairs\"\"\"\n",
        "    n_pairs = len(pairs)\n",
        "    input_ids = torch.zeros(n_pairs, max_input_length, dtype=torch.long)\n",
        "    target_ids = torch.zeros(n_pairs, max_output_length, dtype=torch.long)\n",
        "    for idx, (src, tgt) in enumerate(pairs):\n",
        "        src_indices = sentence_to_indices(src, src_vocab, max_input_length)\n",
        "        tgt_indices = sentence_to_indices(tgt, tgt_vocab, max_output_length)\n",
        "        input_ids[idx] = torch.tensor(src_indices, dtype=torch.long)\n",
        "        target_ids[idx] = torch.tensor(tgt_indices, dtype=torch.long)\n",
        "    dataset = torch.utils.data.TensorDataset(input_ids, target_ids)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    return dataloader\n",
        "\n",
        "def train_model(encoder, decoder, connector,\n",
        "                src_vocab, tgt_vocab,\n",
        "                pairs,\n",
        "                n_epochs=80,\n",
        "                batch_size=32,\n",
        "                max_input_length=10,\n",
        "                max_output_length=15,\n",
        "                learning_rate=0.0005,\n",
        "                teacher_forcing_ratio=0.8,\n",
        "                clip=0.5):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    encoder.to(device)\n",
        "    decoder.to(device)\n",
        "    connector.to(device)\n",
        "    train_dataloader = create_dataloader(pairs, src_vocab, tgt_vocab, batch_size, max_input_length, max_output_length)\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate, weight_decay=1e-6, eps=1e-8)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate, weight_decay=1e-6, eps=1e-8)\n",
        "    connector_optimizer = optim.Adam(connector.parameters(), lr=learning_rate, weight_decay=1e-6, eps=1e-8)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_token, reduction='mean', label_smoothing=0.1)\n",
        "    all_losses = []\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "        connector.train()\n",
        "        epoch_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        for input_tensor, target_tensor in train_dataloader:\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            target_tensor = target_tensor.to(device)\n",
        "\n",
        "            encoder_optimizer.zero_grad()\n",
        "            decoder_optimizer.zero_grad()\n",
        "            connector_optimizer.zero_grad()\n",
        "\n",
        "            batch_size = input_tensor.size(0)\n",
        "            target_length = target_tensor.size(1)\n",
        "\n",
        "            encoder_outputs, (encoder_hidden, encoder_cell) = encoder(input_tensor)\n",
        "            decoder_hidden, decoder_cell = connector(encoder_hidden, encoder_cell)\n",
        "            decoder_input = torch.tensor([SOS_token] * batch_size, device=device)\n",
        "            all_losses_batch = []\n",
        "            use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            if use_teacher_forcing:\n",
        "                for t in range(min(target_length - 1, max_output_length)):\n",
        "                    decoder_output, (decoder_hidden, decoder_cell) = decoder(\n",
        "                        decoder_input, (decoder_hidden, decoder_cell)\n",
        "                    )\n",
        "                    if t < target_length - 1:\n",
        "                        step_loss = criterion(decoder_output, target_tensor[:, t])\n",
        "                        if not torch.isnan(step_loss):\n",
        "                            all_losses_batch.append(step_loss)\n",
        "                    decoder_input = target_tensor[:, t]\n",
        "            else:\n",
        "                for t in range(max_output_length):\n",
        "                    decoder_output, (decoder_hidden, decoder_cell) = decoder(\n",
        "                        decoder_input, (decoder_hidden, decoder_cell)\n",
        "                    )\n",
        "                    if t < target_length - 1:\n",
        "                        step_loss = criterion(decoder_output, target_tensor[:, t])\n",
        "                        if not torch.isnan(step_loss):\n",
        "                            all_losses_batch.append(step_loss)\n",
        "                    _, topi = decoder_output.topk(1)\n",
        "                    decoder_input = topi.squeeze().detach()\n",
        "                    if (decoder_input == EOS_token).all():\n",
        "                        break\n",
        "\n",
        "            loss = torch.stack(all_losses_batch).mean()\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "            torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "            torch.nn.utils.clip_grad_norm_(connector.parameters(), clip)\n",
        "\n",
        "            encoder_optimizer.step()\n",
        "            decoder_optimizer.step()\n",
        "            connector_optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            batch_count += 1\n",
        "\n",
        "        if batch_count > 0:\n",
        "            avg_epoch_loss = epoch_loss / batch_count\n",
        "            all_losses.append(avg_epoch_loss)\n",
        "            print(f\"Epoch {epoch}/{n_epochs} | Average Loss: {avg_epoch_loss:.4f}\")\n",
        "\n",
        "    return all_losses\n",
        "\n",
        "def evaluate(encoder, decoder, connector, sentence, src_vocab, tgt_index2word,\n",
        "             max_input_length, max_output_length, device):\n",
        "    \"\"\"Generate translation for a single sentence\"\"\"\n",
        "    input_indices = sentence_to_indices(sentence, src_vocab, max_input_length)\n",
        "    input_tensor = torch.tensor(input_indices, dtype=torch.long, device=device).unsqueeze(0)\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    connector.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, (encoder_hidden, encoder_cell) = encoder(input_tensor)\n",
        "        decoder_hidden, decoder_cell = connector(encoder_hidden, encoder_cell)\n",
        "        decoder_input = torch.tensor([SOS_token], device=device)\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_output_length):\n",
        "            decoder_output, (decoder_hidden, decoder_cell) = decoder(\n",
        "                decoder_input, (decoder_hidden, decoder_cell)\n",
        "            )\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            token = topi.item()\n",
        "\n",
        "            if token == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            elif token != PAD_token:\n",
        "                decoded_words.append(tgt_index2word[token])\n",
        "\n",
        "            decoder_input = topi.detach()\n",
        "\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    connector.train()\n",
        "    return decoded_words\n",
        "\n",
        "def evaluate_sample(encoder, decoder, connector, src_vocab, tgt_vocab, sentence,\n",
        "                    max_input_length, max_output_length, device):\n",
        "    \"\"\"Evaluate and print a sample translation\"\"\"\n",
        "    tgt_index2word = {idx: word for word, idx in tgt_vocab.items()}\n",
        "    print(\"\\nSample Translation:\")\n",
        "    print(f\"Input: {sentence}\")\n",
        "    output_words = evaluate(encoder, decoder, connector, sentence, src_vocab, tgt_index2word,\n",
        "                            max_input_length, max_output_length, device)\n",
        "    output_sentence = ' '.join(output_words)\n",
        "    if '<EOS>' in output_sentence:\n",
        "        output_sentence = output_sentence[:output_sentence.index('<EOS>')]\n",
        "        print(\"EOS predicted\")\n",
        "\n",
        "    print(f\"Output: {output_sentence}\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "xsFZQ4ajn2_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def main():\n",
        "    hidden_size = 128\n",
        "    num_layers = 1\n",
        "    dropout = 0.2\n",
        "    batch_size = 16\n",
        "    n_epochs = 100\n",
        "    learning_rate = 0.001\n",
        "    teacher_forcing_ratio = 0.8\n",
        "    max_input_length = 10\n",
        "    max_output_length = 15\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "    pairs = load_sentence_pairs('processed_eng_fra.txt')\n",
        "\n",
        "    train_pairs, test_pairs = train_test_split(pairs, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(\"Building vocabularies...\")\n",
        "    src_vocab, src_index2word, tgt_vocab, tgt_index2word, src_size, tgt_size = build_vocab_from_data(pairs)\n",
        "\n",
        "    encoder = EncoderRNN(src_size, hidden_size, num_layers, dropout)\n",
        "    decoder = DecoderRNN(hidden_size, tgt_size, num_layers, dropout)\n",
        "    connector = EncoderDecoderConnector(hidden_size, hidden_size, num_layers)\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    train_model(\n",
        "        encoder, decoder, connector,\n",
        "        src_vocab, tgt_vocab, train_pairs,\n",
        "        n_epochs=n_epochs,\n",
        "        batch_size=batch_size,\n",
        "        max_input_length=max_input_length,\n",
        "        max_output_length=max_output_length,\n",
        "        learning_rate=learning_rate,\n",
        "        teacher_forcing_ratio=teacher_forcing_ratio\n",
        "    )\n",
        "\n",
        "    print(\"\\nEvaluating on 10 random test samples:\")\n",
        "    random.shuffle(test_pairs)\n",
        "    for i in range(min(10, len(test_pairs))):\n",
        "        src, tgt = test_pairs[i]\n",
        "        output_words = evaluate(encoder, decoder, connector, src, src_vocab, tgt_index2word,\n",
        "                                max_input_length, max_output_length, device)\n",
        "        output_sentence = ' '.join(output_words).replace('<EOS>', '')\n",
        "        print(f\"\\nInput:  {src}\")\n",
        "        print(f\"Target: {tgt}\")\n",
        "        print(f\"Output: {output_sentence}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    torch.save({\n",
        "        'encoder_state_dict': encoder.state_dict(),\n",
        "        'decoder_state_dict': decoder.state_dict(),\n",
        "        'connector_state_dict': connector.state_dict(),\n",
        "        'src_vocab': src_vocab,\n",
        "        'tgt_vocab': tgt_vocab,\n",
        "        'src_index2word': src_index2word,\n",
        "        'tgt_index2word': tgt_index2word,\n",
        "    }, 'seq2seq_model.pt')\n",
        "    print(\"Model saved to seq2seq_model.pt\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V7BTJNT_eWq",
        "outputId": "b4a15c5d-c88f-49f1-dd8c-d75f888bcdd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Building vocabularies...\n",
            "Starting training...\n",
            "Epoch 1/100 | Average Loss: 4.9196\n",
            "Epoch 2/100 | Average Loss: 4.4319\n",
            "Epoch 3/100 | Average Loss: 4.2186\n",
            "Epoch 4/100 | Average Loss: 4.0630\n",
            "Epoch 5/100 | Average Loss: 3.9356\n",
            "Epoch 6/100 | Average Loss: 3.8279\n",
            "Epoch 7/100 | Average Loss: 3.7348\n",
            "Epoch 8/100 | Average Loss: 3.6596\n",
            "Epoch 9/100 | Average Loss: 3.5724\n",
            "Epoch 10/100 | Average Loss: 3.4162\n",
            "Epoch 11/100 | Average Loss: 3.3514\n",
            "Epoch 12/100 | Average Loss: 3.2612\n",
            "Epoch 13/100 | Average Loss: 3.2140\n",
            "Epoch 14/100 | Average Loss: 3.0584\n",
            "Epoch 15/100 | Average Loss: 3.0649\n",
            "Epoch 16/100 | Average Loss: 3.0570\n",
            "Epoch 17/100 | Average Loss: 3.0194\n",
            "Epoch 18/100 | Average Loss: 2.8732\n",
            "Epoch 19/100 | Average Loss: 2.9340\n",
            "Epoch 20/100 | Average Loss: 2.8854\n",
            "Epoch 21/100 | Average Loss: 2.8497\n",
            "Epoch 22/100 | Average Loss: 2.7914\n",
            "Epoch 23/100 | Average Loss: 2.6690\n",
            "Epoch 24/100 | Average Loss: 2.7513\n",
            "Epoch 25/100 | Average Loss: 2.7667\n",
            "Epoch 26/100 | Average Loss: 2.6297\n",
            "Epoch 27/100 | Average Loss: 2.6316\n",
            "Epoch 28/100 | Average Loss: 2.6704\n",
            "Epoch 29/100 | Average Loss: 2.6524\n",
            "Epoch 30/100 | Average Loss: 2.5655\n",
            "Epoch 31/100 | Average Loss: 2.5958\n",
            "Epoch 32/100 | Average Loss: 2.4820\n",
            "Epoch 33/100 | Average Loss: 2.5143\n",
            "Epoch 34/100 | Average Loss: 2.4546\n",
            "Epoch 35/100 | Average Loss: 2.3956\n",
            "Epoch 36/100 | Average Loss: 2.4178\n",
            "Epoch 37/100 | Average Loss: 2.3899\n",
            "Epoch 38/100 | Average Loss: 2.3980\n",
            "Epoch 39/100 | Average Loss: 2.3579\n",
            "Epoch 40/100 | Average Loss: 2.3238\n",
            "Epoch 41/100 | Average Loss: 2.3653\n",
            "Epoch 42/100 | Average Loss: 2.3777\n",
            "Epoch 43/100 | Average Loss: 2.2759\n",
            "Epoch 44/100 | Average Loss: 2.3953\n",
            "Epoch 45/100 | Average Loss: 2.2442\n",
            "Epoch 46/100 | Average Loss: 2.2503\n",
            "Epoch 47/100 | Average Loss: 2.2499\n",
            "Epoch 48/100 | Average Loss: 2.2564\n",
            "Epoch 49/100 | Average Loss: 2.2306\n",
            "Epoch 50/100 | Average Loss: 2.2373\n",
            "Epoch 51/100 | Average Loss: 2.1798\n",
            "Epoch 52/100 | Average Loss: 2.1879\n",
            "Epoch 53/100 | Average Loss: 2.1275\n",
            "Epoch 54/100 | Average Loss: 2.1375\n",
            "Epoch 55/100 | Average Loss: 2.1532\n",
            "Epoch 56/100 | Average Loss: 2.0985\n",
            "Epoch 57/100 | Average Loss: 2.0833\n",
            "Epoch 58/100 | Average Loss: 2.0968\n",
            "Epoch 59/100 | Average Loss: 2.0468\n",
            "Epoch 60/100 | Average Loss: 2.0607\n",
            "Epoch 61/100 | Average Loss: 2.0450\n",
            "Epoch 62/100 | Average Loss: 2.0777\n",
            "Epoch 63/100 | Average Loss: 2.0766\n",
            "Epoch 64/100 | Average Loss: 2.0240\n",
            "Epoch 65/100 | Average Loss: 2.0176\n",
            "Epoch 66/100 | Average Loss: 2.0410\n",
            "Epoch 67/100 | Average Loss: 1.9653\n",
            "Epoch 68/100 | Average Loss: 1.9625\n",
            "Epoch 69/100 | Average Loss: 2.0790\n",
            "Epoch 70/100 | Average Loss: 1.9330\n",
            "Epoch 71/100 | Average Loss: 1.9096\n",
            "Epoch 72/100 | Average Loss: 1.9379\n",
            "Epoch 73/100 | Average Loss: 1.9181\n",
            "Epoch 74/100 | Average Loss: 1.9448\n",
            "Epoch 75/100 | Average Loss: 1.9664\n",
            "Epoch 76/100 | Average Loss: 1.8944\n",
            "Epoch 77/100 | Average Loss: 1.9154\n",
            "Epoch 78/100 | Average Loss: 1.9085\n",
            "Epoch 79/100 | Average Loss: 1.8544\n",
            "Epoch 80/100 | Average Loss: 1.8725\n",
            "Epoch 81/100 | Average Loss: 1.8786\n",
            "Epoch 82/100 | Average Loss: 1.8474\n",
            "Epoch 83/100 | Average Loss: 1.8308\n",
            "Epoch 84/100 | Average Loss: 1.8346\n",
            "Epoch 85/100 | Average Loss: 1.8537\n",
            "Epoch 86/100 | Average Loss: 1.8212\n",
            "Epoch 87/100 | Average Loss: 1.7875\n",
            "Epoch 88/100 | Average Loss: 1.7958\n",
            "Epoch 89/100 | Average Loss: 1.7985\n",
            "Epoch 90/100 | Average Loss: 1.7829\n",
            "Epoch 91/100 | Average Loss: 1.7399\n",
            "Epoch 92/100 | Average Loss: 1.8098\n",
            "Epoch 93/100 | Average Loss: 1.7431\n",
            "Epoch 94/100 | Average Loss: 1.7573\n",
            "Epoch 95/100 | Average Loss: 1.7802\n",
            "Epoch 96/100 | Average Loss: 1.7442\n",
            "Epoch 97/100 | Average Loss: 1.7518\n",
            "Epoch 98/100 | Average Loss: 1.7459\n",
            "Epoch 99/100 | Average Loss: 1.7371\n",
            "Epoch 100/100 | Average Loss: 1.7087\n",
            "\n",
            "Evaluating on 10 random test samples:\n",
            "\n",
            "Input:  she s pregnant \n",
            "Target: elle attend un heureux evenement\n",
            "Output: <sos> elle est enceinte \n",
            "--------------------------------------------------\n",
            "\n",
            "Input:  i m sorry i don t recognize you \n",
            "Target: je suis desole je ne vous remets pas\n",
            "Output: <sos> je suis desole je ne vous reconnais pas \n",
            "--------------------------------------------------\n",
            "\n",
            "Input:  he s overconfident \n",
            "Target: il a trop confiance en lui meme\n",
            "Output: <sos> il est en train de lire \n",
            "--------------------------------------------------\n",
            "\n",
            "Input:  i m feeling confused \n",
            "Target: je me sens confus\n",
            "Output: <sos> je me sens confuse \n",
            "--------------------------------------------------\n",
            "\n",
            "Input:  i m at tom s house \n",
            "Target: je suis chez tom\n",
            "Output: <sos> je suis desole pour tout ce \n",
            "--------------------------------------------------\n",
            "\n",
            "Input:  he is playing in his room \n",
            "Target: il joue dans sa chambre\n",
            "Output: <sos> il travaille en un roman policier \n",
            "--------------------------------------------------\n",
            "\n",
            "Input:  you are very rich \n",
            "Target: vous etes tres riche\n",
            "Output: <sos> vous etes tres riches \n",
            "--------------------------------------------------\n",
            "\n",
            "Input:  i m just waiting for a friend \n",
            "Target: j attends juste un ami\n",
            "Output: <sos> j attends juste une amie \n",
            "--------------------------------------------------\n",
            "\n",
            "Input:  he s certain to succeed \n",
            "Target: c est sur qu il reussira\n",
            "Output: <sos> il est sur de ses parents \n",
            "--------------------------------------------------\n",
            "\n",
            "Input:  we are his sons \n",
            "Target: nous sommes ses fils\n",
            "Output: <sos> nous sommes desormais maries \n",
            "--------------------------------------------------\n",
            "Model saved to seq2seq_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reference for the above code are:\n",
        "\n",
        "https://docs.pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial -> pytorch tutorial on seq2seq translation.\n",
        "\n",
        "https://github.com/astorfi/sequence-to-sequence-from-scratch/tree/master -> tutorial made by Sina Torfi\n"
      ],
      "metadata": {
        "id": "4svlgEWgMBj1"
      }
    }
  ]
}